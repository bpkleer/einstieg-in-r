---
title: "Regression Diagnostics"  # Page title
weight: 301  # Custom weight
menuTitle: "Regression Diagnostics" # Short title if the title is too long
tags: ["regression diagnostics"]  # Insert tags here; abbreviation of what happens on the page
---

{{% buttonShare href=\"https\:\/\/gitlab.com\/bpkleer\/einstieg-in-statistik\/issues\/new?issue[title]=\" icon=\"fas fa-bug\" %}} {{% /buttonShare %}} 

{{% buttonShare href=\"mailto\:\" icon=\"fas fa-paper-plane\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/t.me\/share\/url?url=\" icon=\"fab fa-telegram\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/api.whatsapp.com\/send?text=\" icon=\"fab fa-whatsapp\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/twitter.com\/share?url=\" icon=\"fab fa-x-twitter\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/www.facebook.com\/sharer\/sharer.php?u=\" icon=\"fab fa-facebook\" %}} {{% /buttonShare %}}

{{% button href=\"https\:\/\/bmc.link\/bpkleerw\" icon=\"fa-solid fa-beer-mug-empty\" %}} {{% /button %}}

In this chapter, the assumptions of **linear regression** are tested. The starting point is the model `olsModel2` from the previous section.

$stfdem_i = \beta_0 + \beta_1*stfeco_i + \beta_2*trstlgl_i + e_i$ (olsModel2)

Load the regression model into the **environment** or recalculate the above-mentioned model.

For `olsModel2`, we obtain the following regression equation:

$$ stfdem_i = 0.67658 + 0.87361 * stfeco_i - 0.04212 * trstlgl_i + e_i $$

The components of the prediction are:

$$ \widehat{stfdem_i} = 0.67658 + 0.87361 * stfeco_i - 0.04212 * trstlgl_i $$

{{% tabs %}}
{{% tab name=\"Question\" %}}
1. What is the effect of `stfeco`?

2. What value does the model predict for a person who indicates satisfaction with economic performance as $10$ and trust in the legal system as $5$?

{{% /tab %}}
{{% tab name=\"Solution\" %}}
1. The effect of `stfeco` is $0.87361$.

2. $\hat{stfdem} = 0.67658 + 0.87361 * 10 - 0.04212 * 5 = 9.20208$
{{% /tab %}}
{{% /tabs %}}

## Assumptions of Linear Regression

As social scientists, we calculate models that need to be tested for the mathematical assumptions. There are a number of functions with which we can calculate **regression diagnostics**. Since we rarely have perfect datasets in the social sciences (non-response, `NA's`), these functions are often too restrictive. In practice, we often decide on an approximation to the assumptions rather than whether the assumptions are fully met. We often check if possible violations are *small* enough for the assumption to hold.

**These are the assumptions of linear regression:**
{{% tabs %}}
{{% tab name="Assumptions" %}}
1. linear relationship

2. $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$

3. $Var(\epsilon_i) = \sigma^2$ (**Homoscedasticity**)

4. $Cov(\epsilon_i, \epsilon_j) = 0, i \neq j$ (**Autocorrelation**)

5. no linear dependence among the independent variables (**Multicollinearity**)

6. no influential cases
{{% /tab %}}
{{% tab name="Effects of Violation" %}}
1. biased estimators

2. invalid significance tests, biased estimators

3. biased estimators

4. inefficient estimation

5. biased estimators

6. biased estimators
{{% /tab %}}
{{% tab name="Possible Solutions" %}}
1. non-linear transformation

2. *nothing!*

3. transformation of the dependent variable (or the linear equation)

4. non-linear transformation

5. remove variables

6. remove observations (but must be theoretically justifiable!)
{{% /tab %}}
{{% tab name="Testing Procedure" %}}
1. Plot inspection

2. Plot inspection (Shapiro-Wilk test)

3. Breusch-Pagan test

4. Durbin-Watson statistic

5. Correlation between independent variables as well as VIF / Tolerance factor

6. Cook's D
{{% /tab %}}
{{% /tabs %}}

In the following pages, you will test the assumptions step by step.
