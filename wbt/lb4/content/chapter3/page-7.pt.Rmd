---
title: "Assunção 6: Casos Influentes"  # Título da página
weight: 307  # Peso individual
menuTitle: "Casos Influentes" # Se o título for longo, use um título curto aqui
tags: ["diagnóstico de regressão", "casos influentes"]  # Insira tags aqui; Palavra curta que descreve o que acontece na página
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,   # Code wird angezeigt
  eval = FALSE,  # Code wird nicht ausgeführt
  message = FALSE, # Messages werden nicht angezeigt
  warnings = FALSE # warnings werden nicht angezeigt
)

library("modelsummary")

pss <- readRDS("./data/pss.rds")

olsModel2 <- lm(
  stfdem ~ 1 + stfeco + trstlgl,   
  data = pss
)      
```

{{% buttonShare href=\"https\:\/\/gitlab.com\/bpkleer\/einstieg-in-statistik\/issues\/new?issue[title]=\" icon=\"fas fa-bug\" %}} {{% /buttonShare %}}  

{{% buttonShare href=\"mailto\:\" icon=\"fas fa-paper-plane\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/t.me\/share\/url?url=\" icon=\"fab fa-telegram\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/api.whatsapp.com\/send?text=\" icon=\"fab fa-whatsapp\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/twitter.com\/share?url=\" icon=\"fab fa-x-twitter\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/www.facebook.com\/sharer\/sharer.php?u=\" icon=\"fab fa-facebook\" %}} {{% /buttonShare %}}

{{% button href=\"https\:\/\/bmc.link\/bpkleerw\" icon=\"fa-solid fa-beer-mug-empty\" %}} {{% /button %}}

Para verificar casos influentes, usamos novamente os resíduos. Aqui, dois valores são relevantes: **Alavancagem** e **Distância de Cook (Cook's D)**. Como **Cook's D** é baseado em parte na **alavancagem**, focamos diretamente em **Cook's D**.

{{% tabs %}}
{{% tab name=\"Alavancagem\" %}}

- É a derivada parcial do valor estimado $i$-ésimo da variável dependente $\hat{y_i}$ em relação ao valor medido $i$-ésimo da variável dependente $y_i$ 

- O grau em que o valor medido $i$-ésimo influencia o valor ajustado $i$-ésimo

- "Anormalidade" dos $x$'s

- $h_{ii} = \frac{\partial \hat{y_i}}{\partial y_i}$

- Um caso é considerado influente se $h_{ii} > .2$
{{% /tab %}}
{{% tab name=\"Distância de Cook (Cook's D)\" %}}

- É a distância pela qual um valor estimado se move dentro da elipse de confiança que assume a região de valores plausíveis para o parâmetro


- Avalia a influência (o quanto um caso altera o modelo de regressão)

- $D_i = \frac{ \sum_{j=1}^n (\hat{y}_j - \hat{y}_{j(i)})}{p * s^2}$, onde $p$ é o número de parâmetros

- Classificado como influente se $D_i > \bar{D} *3$
{{% /tab %}}
{{% /tabs %}}

Primeiro, podemos simplesmente plotar **Cook's D**. Para isso, utilize novamente a função `plot()`, passe o modelo de regressão como argumento e defina o valor `4` no segundo argumento:
```{r cooksd, eval=TRUE}
plot(
  olsModel2,
  4
)
```

**Limites**:

$D_i < 1$: nenhum único caso

$\frac{4}{4890} \approx 0.0008179959$: muitos casos

$\bar{D} * 3 \approx 0.0005895857$: muitos casos

Também podemos plotar **Cook's D** versus **leverage** e desenhar linhas para os limites:
```{r eval=FALSE}
plot(
  olsModel2, 
  6
)

abline(
  h = 3 * mean(cooks.distance(olsModel2), na.rm = TRUE), 
  col = "chartreuse4", 
  lty = 6,  # Grenze Cook's D
  lwd = 2
)

abline(
  v = 2 * (2 + 1) / 2393, 
  col = "chartreuse4", 
  lty = 6,  # Grenze leverage
  lwd = 2
) 
```

Agora, para verificar se esses casos teoricamente potencialmente influentes são realmente influentes, recalculamos o modelo excluindo essas observações.

Para isso, precisamos de um conjunto de dados com o mesmo comprimento que nossa estimativa do modelo:
```{r rerun, eval=TRUE}
nobs(olsModel2)

ccol <- c(
  "stfdem",
  "stfeco",
  "trstlgl"
)   

pss2 <- pss[complete.cases(pss[,ccol]),]

dim(pss2)
```

Agora podemos adicionar os valores de **leverage** (*hat values*) e **Cook's D** ao conjunto de dados.

```{r hats, eval=TRUE}
pss2$hats <- hatvalues(olsModel2)    

pss2$cooksd <- cooks.distance(olsModel2)  
```

Tudo o que segue requer um entendimento mais profundo, especialmente o entendimento de loops e condições *if* do [Bloco de Aprendizagem 2](https://lehre.bpkleer.de/statsplus/lb2/chapter3/). **Mas** como mencionado, este capítulo é adicional e não fará parte do exercício de laboratório obrigatório.

Agora, para excluir os casos potencialmente influentes, precisamos de um indicador que nos mostre se o caso é influente de acordo com os critérios ($1$) ou não ($0$): No loop, primeiro verificamos se o valor do caso está acima do limite. Se sim, atribuímos o valor 1 para a variável `leverage` ou para Cook's D a variável `influence`.
```{r loop, eval=TRUE}
for (i in 1:dim(pss2)[1]) {   
if (pss2$hats[i] > (2*(2+1)/dim(pss2)[1])) {
   pss2$leverage[i] = 1
} else {
   pss2$leverage[i] = 0
}
}

for (i in 1:dim(pss2)[1]) {
   if (pss2$cooksd[i] > (3*mean(pss2$cooksd))) {
      pss2$influence[i] = 1
   } else {
      pss2$influence[i] = 0
   }
}
```

Nós podemos recalcular o modelo com o conjunto de dados reduzido: Aqui, estamos restringindo o conjunto de dados aos casos em que as novas variáveis criadas, `alavancagem` e `influência`, têm o valor `0`, ou seja, não são influentes.
```{r model-rerun, eval=TRUE}
olsModel2Re <- lm(
  stfdem ~ 1 + stfeco + trstlgl,  
  data = pss2[pss2$leverage==0 & pss2$influence==0,]
)
```

Para descobrir quantos casos foram excluídos, você pode fazer a seguinte subtração simples:
```{r diff, eval=TRUE}
nobs(olsModel2Re) - nobs(olsModel2)
```

Portanto, foram excluídos 736 casos. Muitos!

Vamos analisar o resultado do modelo redefinido com `summary()`:
**Modelo Redefinido**
```{r model-check, eval=TRUE}
summary(olsModel2Re)
```
Mas será que isso difere do modelo antigo? Para isso, vamos usar a função `modelsummary()` que já conhecemos. Em uma tabela, podemos comparar os valores melhor. É importante verificar se os erros padrão ou os coeficientes mudam.
```{r model-check2, eval=TRUE}
modelsummary(
  list(
    olsModel2, 
    olsModel2Re
  ),
  stars = TRUE
)
```
$\Rightarrow$ Você pode ver que o coeficiente para o *intercept* e para `stfeco` mudam. O *intercept* diminui, enquanto o efeito de `stfdem` aumenta. Os erros padrão (valores entre parênteses) não mudam.

Se observarmos grandes mudanças, os casos filtrados precisam ser inspecionados mais detalhadamente. Não podemos simplesmente excluir casos com base em condições matemáticas.

Para descobrir quais casos são, você pode programar um loop novamente:
```{r extract-influentials, eval=TRUE}
levInfluential <- c()
cookInfluential <- c()
allInfluential <- c()

# nur für leverage
for (i in 1:dim(pss2)[1]) {
  if (pss2$leverage[i] == 1) {
    levInfluential <- c(levInfluential, pss2$idno[i])
  }
}

# nur für Cook's D
for (i in 1:dim(pss2)[1]) {
  if (pss2$influence[i] == 1) {
    cookInfluential <- c(cookInfluential, pss2$idno[i])
  }
}

# für beides
for (i in 1:dim(pss2)[1]) {
  if (pss2$leverage[i] == 1 & pss2$influence[i] == 1) {
    allInfluential <- c(allInfluential, pss2$idno[i])
  }
}
```

Como resultado, você obterá três vetores, cada um contendo os casos influentes:
```{r result-influential, eval=TRUE}
levInfluential

cookInfluential

allInfluential
```

Em seguida, você pode examinar mais de perto os pares de valores nas variáveis da regressão por caso!

Isso conclui a diagnóstico de regressão. Com os seis passos, você pode garantir que sua análise de regressão não esteja distorcida devido a uma violação de pressupostos.

Please provide the Markdown content you would like me to translate into Brazilian Portuguese.
