---
title: "Standardized Regression Coefficients"  # Page title
weight: 201  # Custom weight 
menuTitle: "Std. Coefficients" # Short title if the main title is too long
tags: ["regression", "regression coefficients", "standardized"]  # Tags to describe the content of the page
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,   # Code wird angezeigt
  eval = FALSE,  # Code wird nicht ausgef√ºhrt
  message = FALSE, # Messages werden nicht angezeigt
  warnings = FALSE # warnings werden nicht angezeigt
)

library("tidyverse")

pss <- readRDS("./data/pss.rds")

olsModel <- lm(
  stfdem ~ 1 + stfeco, #Formel der Regression
  data = pss # Datenobjekt
)  

olsModel2 <- lm(
  stfdem ~ 1 + stfeco + trstlgl,   
  data = pss
)      
```

{{% buttonShare href=\"https\:\/\/gitlab.com\/bpkleer\/einstieg-in-statistik\/issues\/new?issue[title]=\" icon=\"fas fa-bug\" %}} {{% /buttonShare %}} 

{{% buttonShare href=\"mailto\:\" icon=\"fas fa-paper-plane\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/t.me\/share\/url?url=\" icon=\"fab fa-telegram\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/api.whatsapp.com\/send?text=\" icon=\"fab fa-whatsapp\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/twitter.com\/share?url=\" icon=\"fab fa-x-twitter\" %}} {{% /buttonShare %}}

{{% buttonShare href=\"https\:\/\/www.facebook.com\/sharer\/sharer.php?u=\" icon=\"fab fa-facebook\" %}} {{% /buttonShare %}}

{{% button href=\"https\:\/\/bmc.link\/bpkleerw\" icon=\"fa-solid fa-beer-mug-empty\" %}} {{% /button %}}

In Statistics I, you have already learned about z-standardization to compare distributions of variables more effectively. Z-standardization recodes a variable to the unit standard deviation, making variables that are z-standardized comparable.

In R, non-standardized variables also yield non-standardized regression coefficients. You have seen this in the interpretation of regression results: you always evaluated in the unit of the variables. The disadvantage of non-standardized variables is that the effects are not comparable in strength. This can only be achieved with standardized variables.

In some (often more complex) models, we want to evaluate the strength of the individual independent variables. Since the variables do not have the same unit, as explained above, this is not easily achievable. However, we can standardize the variables so that all variables have the same unit (standard deviations). For this, it is best to use the `scale()` function from the **tidyverse** (`dplyr`). In more complex regression models or advanced models (such as *Multi-Level Models*), variables are usually standardized before calculating the model. 

Let's take this step now for the variables in `olsModel2`:
```{r scale, eval=TRUE}
pss <- pss %>% 
  mutate(
    stfdemZ = scale(stfdem),
    stfecoZ = scale(stfeco),
    trstlglZ = scale(trstlgl)
  )

```

Next, we calculate the model again with the new variables:
```{r olsM2Z, eval=TRUE}
olsModel2Z <- lm(
  stfdemZ ~ 1 + stfecoZ + trstlglZ,   
  data = pss
)   
```

How do we interpret the result?
```{r eval=TRUE, echo=TRUE}
summary(olsModel2Z)
```

**Result**: With each increase of one standard deviation in `stfeco`, `stfdem` increases by $0.697244$ standard deviations. As can be seen, the interpretation is somewhat cumbersome. But now the individual effects between metric variables can be compared. It becomes apparent that the effect of `stfeco` is stronger than that of `trstlgl` ($0.697244 > |-0.033592|$).
